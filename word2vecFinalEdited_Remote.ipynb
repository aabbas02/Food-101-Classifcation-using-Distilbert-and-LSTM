{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%pip list\n",
    "\n",
    "import sys\n",
    "#from gensim.utils import tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import transformers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import re\n",
    "from utils import *\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#import bert\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import gensim\n",
    "import sys\n",
    "import string\n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torchtext\n",
    "\n",
    "#import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchtext (0.18.0)\n",
      "Available versions: 0.18.0, 0.17.2, 0.16.2, 0.6.0, 0.5.0, 0.4.0, 0.3.1, 0.2.3, 0.2.1, 0.2.0, 0.1.1\n",
      "  INSTALLED: 0.17.2\n",
      "  LATEST:    0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip index is currently an experimental command. It may be removed/changed in a future release without prior warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip index versions torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "absl-py                 2.1.0\n",
      "annotated-types         0.7.0\n",
      "asttokens               2.4.1\n",
      "astunparse              1.6.3\n",
      "blis                    1.0.1\n",
      "catalogue               2.0.10\n",
      "certifi                 2024.8.30\n",
      "charset-normalizer      3.4.0\n",
      "click                   8.1.7\n",
      "cloudpathlib            0.20.0\n",
      "colorama                0.4.6\n",
      "comm                    0.2.2\n",
      "confection              0.1.5\n",
      "contourpy               1.3.1\n",
      "cycler                  0.12.1\n",
      "cymem                   2.0.10\n",
      "debugpy                 1.8.9\n",
      "decorator               5.1.1\n",
      "en_core_web_sm          3.8.0\n",
      "executing               2.1.0\n",
      "filelock                3.16.1\n",
      "flatbuffers             24.3.25\n",
      "fonttools               4.55.0\n",
      "fsspec                  2024.10.0\n",
      "gast                    0.6.0\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.68.0\n",
      "h5py                    3.12.1\n",
      "huggingface-hub         0.26.3\n",
      "idna                    3.10\n",
      "ipykernel               6.29.5\n",
      "ipython                 8.30.0\n",
      "jedi                    0.19.2\n",
      "Jinja2                  3.1.4\n",
      "joblib                  1.4.2\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.7.2\n",
      "keras                   3.7.0\n",
      "kiwisolver              1.4.7\n",
      "langcodes               3.5.0\n",
      "language_data           1.3.0\n",
      "libclang                18.1.1\n",
      "marisa-trie             1.2.1\n",
      "Markdown                3.7\n",
      "markdown-it-py          3.0.0\n",
      "MarkupSafe              3.0.2\n",
      "matplotlib              3.9.2\n",
      "matplotlib-inline       0.1.7\n",
      "mdurl                   0.1.2\n",
      "ml-dtypes               0.4.1\n",
      "mpmath                  1.3.0\n",
      "murmurhash              1.0.11\n",
      "namex                   0.0.8\n",
      "nest-asyncio            1.6.0\n",
      "networkx                3.4.2\n",
      "numpy                   2.0.2\n",
      "opt_einsum              3.4.0\n",
      "optree                  0.13.1\n",
      "packaging               24.2\n",
      "pandas                  2.2.3\n",
      "parso                   0.8.4\n",
      "pillow                  11.0.0\n",
      "pip                     24.2\n",
      "platformdirs            4.3.6\n",
      "plotly                  5.24.1\n",
      "preshed                 3.0.9\n",
      "prompt_toolkit          3.0.48\n",
      "protobuf                5.29.0\n",
      "psutil                  6.1.0\n",
      "pure_eval               0.2.3\n",
      "pydantic                2.10.2\n",
      "pydantic_core           2.27.1\n",
      "Pygments                2.18.0\n",
      "pyparsing               3.2.0\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2024.2\n",
      "pywin32                 308\n",
      "PyYAML                  6.0.2\n",
      "pyzmq                   26.2.0\n",
      "regex                   2024.11.6\n",
      "requests                2.32.3\n",
      "rich                    13.9.4\n",
      "safetensors             0.4.5\n",
      "scikit-learn            1.5.2\n",
      "scipy                   1.13.1\n",
      "setuptools              75.6.0\n",
      "shellingham             1.5.4\n",
      "six                     1.16.0\n",
      "smart-open              7.0.5\n",
      "spacy                   3.8.2\n",
      "spacy-legacy            3.0.12\n",
      "spacy-loggers           1.0.5\n",
      "srsly                   2.4.8\n",
      "stack-data              0.6.3\n",
      "sympy                   1.13.1\n",
      "tenacity                9.0.0\n",
      "tensorboard             2.18.0\n",
      "tensorboard-data-server 0.7.2\n",
      "tensorflow              2.18.0\n",
      "tensorflow-hub          0.16.1\n",
      "tensorflow_intel        2.18.0\n",
      "termcolor               2.5.0\n",
      "tf_keras                2.18.0\n",
      "thinc                   8.3.2\n",
      "threadpoolctl           3.5.0\n",
      "tokenizers              0.20.3\n",
      "torch                   2.2.2\n",
      "torchtext               0.17.2\n",
      "torchvision             0.17.2\n",
      "tornado                 6.4.2\n",
      "tqdm                    4.67.1\n",
      "traitlets               5.14.3\n",
      "transformers            4.46.3\n",
      "typer                   0.14.0\n",
      "typing_extensions       4.12.2\n",
      "tzdata                  2024.2\n",
      "urllib3                 2.2.3\n",
      "wasabi                  1.1.3\n",
      "wcwidth                 0.2.13\n",
      "weasel                  0.4.1\n",
      "Werkzeug                3.1.3\n",
      "wheel                   0.45.1\n",
      "wrapt                   1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class customTextDataset(Dataset):\n",
    "    def __init__(self, path, colnames, vocab=None):\n",
    "        self.data =  pd.read_csv(path, names=colnames, header=None, sep = ',', index_col=False)\n",
    "        self.vocab = vocab\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #To do{\n",
    "        # indent below with if vocab == None: return sentence, label\n",
    "        # if vocab is Not none, return tokens, labels\n",
    "        #}\n",
    "        sentence = remove_tags(self.data.loc[idx].text)\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "        sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        label = self.data.loc[idx].food\n",
    "        return sentence,label\n",
    " \n",
    "    def getHead(self):\n",
    "        print(self.data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "trainData = customTextDataset(path = 'train_titles.csv', colnames=['image_path', 'text', 'food'])\n",
    "trainLoader = DataLoader(trainData,batch_size=5)\n",
    "#trainData.getHead()\n",
    "testData = customTextDataset(path = 'test_titles.csv', colnames=['image_path', 'text', 'food'])\n",
    "testLoader = DataLoader(testData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Length Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\virtual Environments\\food101\\Lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size = 19548\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import io\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en')\n",
    "try:\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "except IOError:\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "vocabIterator = build_vocab_from_iterator([en_tokenizer(str(string_)) for string_,_ in trainLoader],specials=[\"<pad>\"])\n",
    "vocabIterator.set_default_index(vocabIterator.get_stoi()[\"<pad>\"])\n",
    "vocabSize = (vocabIterator.__len__() )\n",
    "print(f\"Vocabulary Size = {vocabSize}\")\n",
    "\n",
    "#def build_vocab_from_counter(data, tokenizer):\n",
    "#    counter = Counter()\n",
    "#    for string_ in data:\n",
    "#        counter.update(tokenizer(str(string_)))\n",
    "#    \n",
    "#    sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "#    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "#    return vocab(ordered_dict=ordered_dict, specials=[\"<blank>\"])\n",
    "\n",
    "\n",
    "#vocab = build_vocab_from_counter(processed_train, en_tokenizer)\n",
    "#vocabSize = (vocab.__len__() )\n",
    "#print(vocabSize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Captions to Tokens to IDs and Assign Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2idNew(listData, maxLen, vocab, tokenizer):\n",
    "    ids = torch.zeros( (len(listData),maxLen) )\n",
    "    # set equal to id of 0/pad vector\n",
    "    pad_id = vocab.get_stoi()[\"<pad>\"]\n",
    "    print(f\"Pad Id = {pad_id}\")\n",
    "    ids[:,:] = torch.tensor(pad_id)\n",
    "    for i in range(len(listData)):\n",
    "        indices = torch.tensor(vocab(tokenizer(str(listData[i]))))\n",
    "        L = min(len(indices),maxLen)\n",
    "        ids[i,:L]  = indices[:L]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('crock pot ladies crock pot apple pie moonshine', 'mom maple apple pie recipe taste of home', 'cookin canuck baked apple pie egg rolls recipe', 'dutch apple pie recipe just pinch recipes', 'our share of the harvest raquo grandma apple pie with oat crumb topping'), ('apple_pie', 'apple_pie', 'apple_pie', 'apple_pie', 'apple_pie')]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "numClasses = 101\n",
    "# optionally downsample by reducing the number of classes \n",
    "#train,test = downSampleData(numClasses, train, test)\n",
    "#countsTrn,countsTst  = classCounts(numClasses, train, test)\n",
    "#processed_train = vec_preprocess_text(train.text.values)\n",
    "#processed_test = vec_preprocess_text(test.text.values)\n",
    "#print(processed_train[0])\n",
    "#print(processed_test[0])\n",
    "# get train and test labels\n",
    "encoder = LabelEncoder()\n",
    "i = 0\n",
    "for data in trainLoader:\n",
    "    if i == 0:\n",
    "        print(data)\n",
    "        print(len(data))\n",
    "    i = i + 1\n",
    "#labels = [label for _,label in trainLoader]\n",
    "#print(labels)\n",
    "encoded_labels_train = encoder.fit_transform([str(label) for _,label in trainLoader])\n",
    "encoded_labels_test = encoder.fit_transform([str(label) for _,label in testLoader])\n",
    "# map train and test tokens to ids\n",
    "maxLen = 32\n",
    "#processed_train = [list(tokenize(processed_train[i])) for i in range(processed_train.shape[0])]\n",
    "#idsTrn = token2id(processed_train, maxLen, w2vModel)\n",
    "#idsTrn = token2idNew([str(string_) for string_,_ in train], maxLen, vocabIterator,en_tokenizer)\n",
    "#processed_test = [list(tokenize(processed_test[i])) for i in range(processed_test.shape[0])]\n",
    "#idsTst = token2id(processed_test, maxLen, w2vModel)\n",
    "#idsTst = token2idNew([str(string_) for string_,_ in test],maxLen, vocabIterator,en_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2nModel(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_size, nClasses, padId):\n",
    "        super(w2nModel, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size,batch_first=True)\n",
    "        #self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.drop1 = nn.Dropout(p = 0.5)\n",
    "        self.FC1 = nn.Linear(hidden_size,256)\n",
    "        self.drop2 = nn.Dropout(p = 0.5)\n",
    "        self.FC2 = nn.Linear(256,nClasses)\n",
    "        self.Relu = torch.nn.ReLU()\n",
    "        self.padId = padId\n",
    "\n",
    "\n",
    "    def forward(self, x_):\n",
    "        x = self.word_embeddings(x_) # input dimensions are (batch size, sqeuenquence length) - output dimensions are (batch size, sequence length, feature size)\n",
    "        x[x_ == self.padId,:] = 0 # set rows, where each row is of dimension equal to feature size, corresponding to pad id = 0\n",
    "        (x,_) = self.LSTM(x)        \n",
    "        x = x[:, -1, :] # gives two dimensional output, not three dimensional output -  we are retaining the last hidden state                        \n",
    "        x = self.drop1(x)               \n",
    "        x = self.Relu(self.FC1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.FC2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Pad Id = 0\n",
      "w2nModel(\n",
      "  (word_embeddings): Embedding(19548, 100)\n",
      "  (LSTM): LSTM(100, 64, batch_first=True)\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      "  (FC1): Linear(in_features=64, out_features=256, bias=True)\n",
      "  (drop2): Dropout(p=0.5, inplace=False)\n",
      "  (FC2): Linear(in_features=256, out_features=101, bias=True)\n",
      "  (Relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "torch.device('cuda:0')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "hidden_size = 64\n",
    "batchSize = 512\n",
    "padId = vocabIterator.get_stoi()[\"<pad>\"]\n",
    "dModel = 100\n",
    "vocabSize = (vocabIterator.__len__() )\n",
    "model = w2nModel(vocab_size = vocabSize, \n",
    "                 embedding_dim = dModel,\n",
    "                 hidden_size=hidden_size, nClasses = numClasses, padId = padId\n",
    "                )\n",
    "\n",
    "#labels_train = torch.tensor([int(encoded_labels_train[i]) for i in range(encoded_labels_train.shape[0])]).long()\n",
    "labels_train = torch.tensor([int(encoded_labels_train[i]) for i in range(encoded_labels_train.shape[0])]).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(token2idNew( [str(string_) for string_,_ in trainLoader], maxLen, vocabIterator,en_tokenizer).int(),\n",
    "                                                labels_train)\n",
    "                                                ),\n",
    "                                           batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "\n",
    "#trainLoader = DataLoader(trainData,batch_size=batchSize,shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.005)\n",
    "lossVals = []\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('crock pot ladies crock pot apple pie moonshine', 'mom maple apple pie recipe taste of home')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#print(labels.shape)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#inputs = inputs.to(device) \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#labels = labels.to(device)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\virtual Environments\\food101\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual Environments\\food101\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36mw2nModel.forward\u001b[1;34m(self, x_)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_):\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# input dimensions are (batch size, sqeuenquence length) - output dimensions are (batch size, sequence length, feature size)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     x[x_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadId,:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# set rows, where each row is of dimension equal to feature size, corresponding to pad id = 0\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     (x,_) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLSTM(x)        \n",
      "File \u001b[1;32mc:\\virtual Environments\\food101\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual Environments\\food101\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\virtual Environments\\food101\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual Environments\\food101\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    for data in trainLoader:\n",
    "        inputs = data[0][:]\n",
    "        labels = data[1][:]\n",
    "        print(data[0][:2])\n",
    "        #print(labels.shape)\n",
    "        #inputs = inputs.to(device) \n",
    "        #labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        lossVals.append(loss.detach().clone().cpu())\n",
    "        optimizer.step()\n",
    "    if epoch%5 == 0:\n",
    "        print(loss)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = torch.tensor([int(encoded_labels_test[i]) for i in range(encoded_labels_test.shape[0])]).long()\n",
    "#labels_train = torch.tensor([int(encoded_labels_train[i]) for i in range(encoded_labels_train.shape[0])]).long()\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(list(zip(idsTst.int(), labels_test)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "# again no gradients needed\n",
    "model.eval()\n",
    "correct_pred = 0\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred += 1\n",
    "\n",
    "accuracy = 100 * float(correct_pred)/ idsTst.shape[0]\n",
    "print(f\"Classification Accuracy is {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols=1)\n",
    "ax.plot(range(len(lossVals)),lossVals)\n",
    "ax.set_xlabel('Iterations',fontsize = 15)\n",
    "ax.set_ylabel('Cross Entropy Loss', fontsize = 15)\n",
    "ax.set_title('Classification Accuracy = {:.2f}%'.format(accuracy),fontsize = 15)\n",
    "path = 'dim_{}_accry_{:.2f}len_{}_hidden_{}'.format(dim,accuracy, maxLen,hidden_size)\n",
    "plt.savefig(path+'.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 5 Most Error-Full Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "checkpoint_path = path+'\\_accrcy_{:.2f}_dim_{}.pt'.format(accuracy,dim)\n",
    "print(checkpoint_path)\n",
    "torch.save(model, checkpoint_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2nModelSVM(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_size, nClasses):\n",
    "        super(w2nModelSVM, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size,batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeddings(x)     # output dimensions is batch size = N x sequence length x feature size\n",
    "        (x,_) = self.LSTM(x)        \n",
    "        x = x[:, -1, :]                 # gives two dimensional output, not three dimensional output\n",
    "        return x\n",
    "\n",
    "torch.device('cuda:0')\n",
    "modelSVM = w2nModelSVM(vocab_size = w2v_weights.shape[0], \n",
    "                 embedding_dim = w2v_weights.shape[1],\n",
    "                 hidden_size=hidden_size, nClasses = numClasses\n",
    "                )\n",
    "modelSVM.word_embeddings.weight.data.copy_(torch.from_numpy(w2v_weights))\n",
    "modelSVM.word_embeddings.weight.requires_grad=False\n",
    "modelSVM.LSTM.load_state_dict(model.LSTM.state_dict())\n",
    "modelSVM.LSTM.requires_grad_=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LSTM Embeddings for Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(encoded_labels_train).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTrn.int(), labels_train)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "trnEmbdngs = np.zeros((idsTrn.shape[0],hidden_size))\n",
    "trnLbls  = np.zeros((idsTrn.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelSVM(inputs)\n",
    "    trnEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    trnLbls[i*batchSize: (i+1)*batchSize] = labels\n",
    "\n",
    "labels_test = torch.tensor(encoded_labels_test).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTst.int(), labels_test)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "tstEmbdngs = np.zeros((idsTst.shape[0],hidden_size))\n",
    "tstLbls  = np.zeros((idsTst.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelSVM(inputs)\n",
    "    tstEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    tstLbls[i*batchSize: (i+1)*batchSize] = labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(decision_function_shape='ovo', kernel = 'linear')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyLnr = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyLnr = clf.score(tstEmbdngs,tstLbls)\n",
    "print(r'Train Accuracy of Linear SVM =', TrnAccrcyLnr)\n",
    "print(TstAccrcyLnr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel='rbf')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyKernel = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyKernel = clf.score(tstEmbdngs,tstLbls)\n",
    "print(TrnAccrcyKernel)\n",
    "print(TstAccrcyKernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM without LSTM - Averaging Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2nModelSVM(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_size, nClasses):\n",
    "        super(w2nModelSVM, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeddings(x)                # output dimensions is batch size = N x sequence length x feature size\n",
    "        x = torch.sum(x,dim=1)/x.shape[1]          # batch size x feature size\n",
    "        return x\n",
    "\n",
    "torch.device('cuda:0')\n",
    "modelw2vAvg = w2nModelSVM(vocab_size = w2v_weights.shape[0], \n",
    "                 embedding_dim = w2v_weights.shape[1],\n",
    "                 hidden_size=hidden_size, nClasses = numClasses\n",
    "                )\n",
    "modelw2vAvg.word_embeddings.weight.data.copy_(torch.from_numpy(w2v_weights))\n",
    "modelw2vAvg.word_embeddings.weight.requires_grad=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(encoded_labels_train).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTrn.int(), labels_train)),\n",
    "                                         batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "trnEmbdngs = np.zeros((idsTrn.shape[0],dim))\n",
    "trnLbls  = np.zeros((idsTrn.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelw2vAvg(inputs)\n",
    "    trnEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    trnLbls[i*batchSize: (i+1)*batchSize] = labels\n",
    "\n",
    "labels_test = torch.tensor(encoded_labels_test).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTst.int(), labels_test)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "tstEmbdngs = np.zeros((idsTst.shape[0],dim))\n",
    "tstLbls  = np.zeros((idsTst.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelw2vAvg(inputs)\n",
    "    tstEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    tstLbls[i*batchSize: (i+1)*batchSize] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel = 'linear')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyLnr = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyLnr = clf.score(tstEmbdngs,tstLbls)\n",
    "print(TrnAccrcyLnr)\n",
    "print(TstAccrcyLnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel='rbf')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyKernel = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyKernel = clf.score(tstEmbdngs,tstLbls)\n",
    "print(TrnAccrcyKernel)\n",
    "print(TstAccrcyKernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
