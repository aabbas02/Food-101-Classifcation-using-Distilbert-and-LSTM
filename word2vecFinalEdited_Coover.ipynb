{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "TensorFlow version:  2.18.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torchtext\n",
    "\n",
    "import sys\n",
    "#from gensim.utils import tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import transformers\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import re\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "import tensorflow_hub as hub\n",
    "from utils import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#import bert\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import gensim\n",
    "import sys\n",
    "import string\n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "#from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>food</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple_pie_0.jpg</th>\n",
       "      <td>Apple pie - Wikipedia</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple_pie_100.jpg</th>\n",
       "      <td>Glazed Apple Pie Squares Recipe | Taste of Home</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple_pie_101.jpg</th>\n",
       "      <td>Mock Apple Pie Recipe - Allrecipes.com</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple_pie_102.jpg</th>\n",
       "      <td>Crock-Pot Ladies  Crock-Pot Apple Pie Moonshine</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple_pie_104.jpg</th>\n",
       "      <td>All-Star Apple Pie Recipe | Taste of Home</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              text       food\n",
       "image_path                                                                   \n",
       "apple_pie_0.jpg                              Apple pie - Wikipedia  apple_pie\n",
       "apple_pie_100.jpg  Glazed Apple Pie Squares Recipe | Taste of Home  apple_pie\n",
       "apple_pie_101.jpg           Mock Apple Pie Recipe - Allrecipes.com  apple_pie\n",
       "apple_pie_102.jpg  Crock-Pot Ladies  Crock-Pot Apple Pie Moonshine  apple_pie\n",
       "apple_pie_104.jpg        All-Star Apple Pie Recipe | Taste of Home  apple_pie"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames=['image_path', 'text', 'food']\n",
    "train = pd.read_csv('train_titles.csv', names=colnames, header=None, sep = ',', index_col=['image_path'])\n",
    "test = pd.read_csv('test_titles.csv', names=colnames, header=None, sep = ',', index_col=['image_path'])\n",
    "# Sort values by 'image_path'\n",
    "test = test.sort_values('image_path')\n",
    "train = train.sort_values('image_path')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 67972\n",
      "test samples: 22716\n",
      "Apple pie - Wikipedia\n",
      "apple pie wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes\n",
    "print(\"train samples:\",train.shape[0])\n",
    "print(\"test samples:\",test.shape[0])\n",
    "vec_preprocess_text = np.vectorize(preprocess_text)\n",
    "processed_train = vec_preprocess_text(train.text.values.tolist() + test.text.values.tolist())\n",
    "print(train.text.values.tolist()[0])\n",
    "print(processed_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchtext in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.18.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext) (4.67.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch>=2.3.0 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext) (2.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchtext) (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (69.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->torchtext) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vm-user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\vm-user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -----------\n",
      "absl-py                  2.1.0\n",
      "aiobotocore              2.13.0\n",
      "aiohttp                  3.9.5\n",
      "aioitertools             0.11.0\n",
      "aiosignal                1.3.1\n",
      "annotated-types          0.7.0\n",
      "asttokens                2.4.1\n",
      "astunparse               1.6.3\n",
      "attrs                    23.2.0\n",
      "azure-common             1.1.28\n",
      "azure-core               1.30.2\n",
      "azure-identity           1.17.0\n",
      "azure-mgmt-compute       31.0.0\n",
      "azure-mgmt-core          1.4.0\n",
      "azure-mgmt-network       25.4.0\n",
      "blis                     1.0.1\n",
      "bokeh                    3.4.1\n",
      "botocore                 1.34.106\n",
      "cachetools               5.3.3\n",
      "catalogue                2.0.10\n",
      "certifi                  2024.2.2\n",
      "cffi                     1.16.0\n",
      "charset-normalizer       3.3.2\n",
      "click                    8.1.7\n",
      "cloudpathlib             0.20.0\n",
      "cloudpickle              3.0.0\n",
      "colorama                 0.4.6\n",
      "comm                     0.2.2\n",
      "confection               0.1.5\n",
      "contourpy                1.2.0\n",
      "cryptography             42.0.8\n",
      "cycler                   0.12.1\n",
      "cymem                    2.0.8\n",
      "dask                     2024.5.0\n",
      "dask-cloudprovider       2022.10.0\n",
      "dask-expr                1.1.0\n",
      "dask-glm                 0.3.2\n",
      "dask-ml                  2024.4.4\n",
      "debugpy                  1.8.1\n",
      "decorator                5.1.1\n",
      "distributed              2024.5.0\n",
      "dm-tree                  0.1.8\n",
      "docker-pycreds           0.4.0\n",
      "en_core_web_sm           3.8.0\n",
      "executing                2.0.1\n",
      "fastjsonschema           2.20.0\n",
      "filelock                 3.13.1\n",
      "flake8                   7.1.1\n",
      "flatbuffers              24.3.25\n",
      "fonttools                4.49.0\n",
      "frozenlist               1.4.1\n",
      "fsspec                   2024.2.0\n",
      "gast                     0.5.4\n",
      "gensim                   4.3.3\n",
      "gitdb                    4.0.11\n",
      "google-api-core          2.19.0\n",
      "google-api-python-client 2.134.0\n",
      "google-auth              2.30.0\n",
      "google-auth-httplib2     0.2.0\n",
      "google-pasta             0.2.0\n",
      "googleapis-common-protos 1.63.1\n",
      "GPUtil                   1.4.0\n",
      "grpcio                   1.62.0\n",
      "h5py                     3.12.1\n",
      "hcloud                   1.35.0\n",
      "httplib2                 0.22.0\n",
      "huggingface-hub          0.26.3\n",
      "idna                     3.6\n",
      "ipykernel                6.29.4\n",
      "ipython                  8.25.0\n",
      "isodate                  0.6.1\n",
      "jedi                     0.19.1\n",
      "Jinja2                   3.1.3\n",
      "jmespath                 1.0.1\n",
      "joblib                   1.4.2\n",
      "jsonpickle               3.2.2\n",
      "jupyter_client           8.6.2\n",
      "jupyter_core             5.7.2\n",
      "keras                    3.7.0\n",
      "kiwisolver               1.4.5\n",
      "langcodes                3.5.0\n",
      "language_data            1.3.0\n",
      "libclang                 16.0.6\n",
      "llvmlite                 0.43.0\n",
      "locket                   1.0.0\n",
      "lz4                      4.3.3\n",
      "marisa-trie              1.2.1\n",
      "Markdown                 3.5.2\n",
      "markdown-it-py           3.0.0\n",
      "MarkupSafe               2.1.5\n",
      "matplotlib               3.8.3\n",
      "matplotlib-inline        0.1.7\n",
      "mccabe                   0.7.0\n",
      "mdurl                    0.1.2\n",
      "ml-dtypes                0.4.1\n",
      "mpmath                   1.3.0\n",
      "msal                     1.28.1\n",
      "msal-extensions          1.1.0\n",
      "msgpack                  1.0.8\n",
      "multidict                6.0.5\n",
      "multipledispatch         1.0.0\n",
      "murmurhash               1.0.10\n",
      "mypy-extensions          1.0.0\n",
      "namex                    0.0.7\n",
      "narwhals                 1.13.3\n",
      "nest-asyncio             1.6.0\n",
      "networkx                 3.2.1\n",
      "numba                    0.60.0\n",
      "numpy                    2.0.2\n",
      "opt-einsum               3.3.0\n",
      "optree                   0.13.1\n",
      "packaging                24.1\n",
      "pandas                   2.2.2\n",
      "parso                    0.8.4\n",
      "partd                    1.4.2\n",
      "pathspec                 0.12.1\n",
      "pillow                   10.2.0\n",
      "pip                      24.2\n",
      "platformdirs             4.2.2\n",
      "plotly                   5.24.1\n",
      "portalocker              2.8.2\n",
      "preshed                  3.0.9\n",
      "prompt_toolkit           3.0.47\n",
      "proto-plus               1.24.0\n",
      "protobuf                 4.25.3\n",
      "psutil                   6.0.0\n",
      "pure-eval                0.2.2\n",
      "pyarrow                  16.1.0\n",
      "pyarrow-hotfix           0.6\n",
      "pyasn1                   0.6.0\n",
      "pyasn1_modules           0.4.0\n",
      "pycodestyle              2.12.1\n",
      "pycparser                2.22\n",
      "pydantic                 2.10.2\n",
      "pydantic_core            2.27.1\n",
      "pyflakes                 3.2.0\n",
      "Pygments                 2.18.0\n",
      "PyJWT                    2.8.0\n",
      "pyparsing                3.1.1\n",
      "python-dateutil          2.9.0.post0\n",
      "python-digitalocean      1.17.0\n",
      "pytz                     2024.1\n",
      "pywin32                  306\n",
      "PyYAML                   6.0.1\n",
      "pyzmq                    26.0.3\n",
      "referencing              0.35.1\n",
      "regex                    2024.11.6\n",
      "requests                 2.31.0\n",
      "rich                     13.7.1\n",
      "rpds-py                  0.21.0\n",
      "rsa                      4.9\n",
      "safetensors              0.4.5\n",
      "scikit-learn             1.5.1\n",
      "scipy                    1.12.0\n",
      "sentencepiece            0.2.0\n",
      "sentry-sdk               2.18.0\n",
      "setproctitle             1.3.3\n",
      "setuptools               69.1.1\n",
      "shellingham              1.5.4\n",
      "six                      1.16.0\n",
      "smart-open               7.0.5\n",
      "smmap                    5.0.1\n",
      "sortedcontainers         2.4.0\n",
      "spacy                    3.8.2\n",
      "spacy-legacy             3.0.12\n",
      "spacy-loggers            1.0.5\n",
      "sparse                   0.15.4\n",
      "srsly                    2.4.8\n",
      "stack-data               0.6.3\n",
      "sympy                    1.13.1\n",
      "tblib                    3.0.0\n",
      "tenacity                 9.0.0\n",
      "tensorboard              2.18.0\n",
      "tensorboard-data-server  0.7.2\n",
      "tensorflow               2.18.0\n",
      "tensorflow-hub           0.16.1\n",
      "tensorflow_intel         2.18.0\n",
      "termcolor                2.4.0\n",
      "tf_keras                 2.18.0\n",
      "thinc                    8.3.2\n",
      "threadpoolctl            3.5.0\n",
      "tokenizers               0.20.3\n",
      "toolz                    0.12.1\n",
      "torch                    2.5.1\n",
      "torch-kmeans             0.2.0\n",
      "torchtext                0.18.0\n",
      "torchvision              0.17.1\n",
      "tornado                  6.4.1\n",
      "tqdm                     4.67.0\n",
      "traitlets                5.14.3\n",
      "transformers             4.46.3\n",
      "typer                    0.14.0\n",
      "typing_extensions        4.12.2\n",
      "tzdata                   2024.1\n",
      "uritemplate              4.1.1\n",
      "urllib3                  2.2.1\n",
      "wasabi                   1.1.3\n",
      "wcwidth                  0.2.13\n",
      "weasel                   0.4.1\n",
      "Werkzeug                 3.0.1\n",
      "wheel                    0.42.0\n",
      "wrapt                    1.16.0\n",
      "xyzservices              2024.4.0\n",
      "yarl                     1.9.4\n",
      "zict                     3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchtext -U\n",
    "%pip list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Length Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listData = [list(tokenize(processed_train[i])) for i in range(processed_train.shape[0])]\n",
    "#lengths = [len(listData[i]) for i in range(len(listData))]\n",
    "#fig,ax = plt.subplots(figsize = (7,5))\n",
    "#ax.hist(lengths,bins = range(0,30,1))\n",
    "#ax.set_ylabel('Counts', fontsize = 11)\n",
    "#ax.set_xlabel('Number of words', fontsize =11)\n",
    "#ax.set_title('Sentence lengths in input data', fontsize = 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Word2vec on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mdim = 100                 \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mw2vModel = word2vec.Word2Vec(listData, vector_size=dim,min_count=1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mprint(w2vModel.wv.most_similar('falafel',topn=3))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocab\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_ops.py:1350\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1345\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "dim = 100                 \n",
    "w2vModel = word2vec.Word2Vec(listData, vector_size=dim,min_count=1)\n",
    "# add default key, that is, value for unknown key, may happen during testing\n",
    "w2vModel.wv.add_vector(0,np.zeros((dim)))\n",
    "w2v_weights = w2vModel.wv.vectors\n",
    "\n",
    "print(w2vModel.wv.most_similar('barbecue',topn=3))\n",
    "print(w2vModel.wv.most_similar('apple',topn=3))\n",
    "print(w2vModel.wv.most_similar('falafel',topn=3))\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import io\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#en_tokenizer = get_tokenizer('spacy', language='en')\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "try:\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "except IOError:\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def build_vocab(data, tokenizer):\n",
    "    counter = Counter()\n",
    "    for string_ in data:\n",
    "        counter.update(tokenizer.tokenizer(str(string_)))\n",
    "    \n",
    "    return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "vocab = build_vocab(processed_train, spacy_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vocab.__len__() )\n",
    "print(vocab.itos[5])\n",
    "dict = vocab.stoi\n",
    "dict[vocab.itos[5]]\n",
    "#print(vocab.itos[5].type)\n",
    "vocab.set_default_index(vocab['<unk>'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Captions to Tokens to IDs and Assign Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2idNew(listData, maxLen, vocab):\n",
    "    ids = torch.zeros( (len(listData),maxLen) )\n",
    "    # set equal to id of 0/pad vector\n",
    "    ids[:,:] = torch.tensor(w2vModel.wv.key_to_index[0])\n",
    "    for i in range(len(listData)):\n",
    "        for j in range(min([maxLen,len(listData[i])])):\n",
    "            ids[i,j] = torch.tensor(w2vModel.wv.key_to_index[listData[i][j]])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = 101\n",
    "# optionally downsample by reducing the number of classes \n",
    "#train,test = downSampleData(numClasses, train, test)\n",
    "countsTrn,countsTst  = classCounts(numClasses, train, test)\n",
    "processed_train = vec_preprocess_text(train.text.values)\n",
    "processed_test = vec_preprocess_text(test.text.values)\n",
    "#print(processed_train[0])\n",
    "#print(processed_test[0])\n",
    "# get train and test labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels_train = encoder.fit_transform(train.food.values)\n",
    "encoded_labels_test = encoder.fit_transform(test.food.values)\n",
    "# map train and test tokens to ids\n",
    "maxLen = 32\n",
    "#processed_train = [list(tokenize(processed_train[i])) for i in range(processed_train.shape[0])]\n",
    "#idsTrn = token2id(processed_train, maxLen, w2vModel)\n",
    "idsTrn = token2idNew(processed_train,maxLen, vocab)\n",
    "#processed_test = [list(tokenize(processed_test[i])) for i in range(processed_test.shape[0])]\n",
    "#idsTst = token2id(processed_test, maxLen, w2vModel)\n",
    "idsTst = token2idNew(processed_test,maxLen, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2nModel(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_size, nClasses):\n",
    "        super(w2nModel, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size,batch_first=True)\n",
    "        #self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.drop1 = nn.Dropout(p = 0.5)\n",
    "        self.FC1 = nn.Linear(hidden_size,256)\n",
    "        self.drop2 = nn.Dropout(p = 0.5)\n",
    "        self.FC2 = nn.Linear(256,nClasses)\n",
    "        self.Relu = torch.nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeddings(x) # output dimensions is batch size = N x sequence length x feature size\n",
    "        (x,_) = self.LSTM(x)        \n",
    "        x = x[:, -1, :] # gives two dimensional output, not three dimensional output\n",
    "        #x = self.bn(x)\n",
    "        x = self.drop1(x)               \n",
    "        x = self.Relu(self.FC1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.FC2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "torch.device('cuda:0')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#device = 'gpu'\n",
    "hidden_size = 64\n",
    "model = w2nModel(vocab_size = w2v_weights.shape[0], \n",
    "                 embedding_dim = w2v_weights.shape[1],\n",
    "                 hidden_size=hidden_size, nClasses = numClasses\n",
    "                )\n",
    "#model.word_embeddings.weight.data.copy_(torch.from_numpy(w2v_weights))\n",
    "#model.word_embeddings.weight.requires_grad=False\n",
    "\n",
    "labels_train = torch.tensor(encoded_labels_train).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTrn.int(), labels_train)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "lossVals = []\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs,labels = data\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        lossVals.append(loss.detach().cpu().numpy())\n",
    "        optimizer.step()\n",
    "    if epoch%5 == 0:\n",
    "        print(loss)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = torch.tensor(encoded_labels_test).long()\n",
    "testLoader = torch.utils.data.DataLoader(list(zip(idsTst.int(), labels_test)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "# again no gradients needed\n",
    "model.eval()\n",
    "correct_pred = 0\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred += 1\n",
    "\n",
    "accuracy = 100 * float(correct_pred)/ idsTst.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols=1)\n",
    "ax.plot(range(len(lossVals)),lossVals)\n",
    "ax.set_xlabel('Iterations',fontsize = 15)\n",
    "ax.set_ylabel('Cross Entropy Loss', fontsize = 15)\n",
    "ax.set_title('Classification Accuracy = {:.2f}%'.format(accuracy),fontsize = 15)\n",
    "path = 'dim_{}_accry_{:.2f}len_{}_hidden_{}'.format(dim,accuracy, maxLen,hidden_size)\n",
    "plt.savefig(path+'.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 5 Most Error-Full Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "checkpoint_path = path+'\\_accrcy_{:.2f}_dim_{}.pt'.format(accuracy,dim)\n",
    "print(checkpoint_path)\n",
    "torch.save(model, checkpoint_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2nModelSVM(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_size, nClasses):\n",
    "        super(w2nModelSVM, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size,batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeddings(x)     # output dimensions is batch size = N x sequence length x feature size\n",
    "        (x,_) = self.LSTM(x)        \n",
    "        x = x[:, -1, :]                 # gives two dimensional output, not three dimensional output\n",
    "        return x\n",
    "\n",
    "torch.device('cuda:0')\n",
    "modelSVM = w2nModelSVM(vocab_size = w2v_weights.shape[0], \n",
    "                 embedding_dim = w2v_weights.shape[1],\n",
    "                 hidden_size=hidden_size, nClasses = numClasses\n",
    "                )\n",
    "modelSVM.word_embeddings.weight.data.copy_(torch.from_numpy(w2v_weights))\n",
    "modelSVM.word_embeddings.weight.requires_grad=False\n",
    "modelSVM.LSTM.load_state_dict(model.LSTM.state_dict())\n",
    "modelSVM.LSTM.requires_grad_=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LSTM Embeddings for Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(encoded_labels_train).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTrn.int(), labels_train)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "trnEmbdngs = np.zeros((idsTrn.shape[0],hidden_size))\n",
    "trnLbls  = np.zeros((idsTrn.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelSVM(inputs)\n",
    "    trnEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    trnLbls[i*batchSize: (i+1)*batchSize] = labels\n",
    "\n",
    "labels_test = torch.tensor(encoded_labels_test).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTst.int(), labels_test)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "tstEmbdngs = np.zeros((idsTst.shape[0],hidden_size))\n",
    "tstLbls  = np.zeros((idsTst.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelSVM(inputs)\n",
    "    tstEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    tstLbls[i*batchSize: (i+1)*batchSize] = labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(decision_function_shape='ovo', kernel = 'linear')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyLnr = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyLnr = clf.score(tstEmbdngs,tstLbls)\n",
    "print(r'Train Accuracy of Linear SVM =', TrnAccrcyLnr)\n",
    "print(TstAccrcyLnr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel='rbf')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyKernel = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyKernel = clf.score(tstEmbdngs,tstLbls)\n",
    "print(TrnAccrcyKernel)\n",
    "print(TstAccrcyKernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM without LSTM - Averaging Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2nModelSVM(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_size, nClasses):\n",
    "        super(w2nModelSVM, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.word_embeddings(x)                # output dimensions is batch size = N x sequence length x feature size\n",
    "        x = torch.sum(x,dim=1)/x.shape[1]          # batch size x feature size\n",
    "        return x\n",
    "\n",
    "torch.device('cuda:0')\n",
    "modelw2vAvg = w2nModelSVM(vocab_size = w2v_weights.shape[0], \n",
    "                 embedding_dim = w2v_weights.shape[1],\n",
    "                 hidden_size=hidden_size, nClasses = numClasses\n",
    "                )\n",
    "modelw2vAvg.word_embeddings.weight.data.copy_(torch.from_numpy(w2v_weights))\n",
    "modelw2vAvg.word_embeddings.weight.requires_grad=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(encoded_labels_train).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTrn.int(), labels_train)),\n",
    "                                         batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "trnEmbdngs = np.zeros((idsTrn.shape[0],dim))\n",
    "trnLbls  = np.zeros((idsTrn.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelw2vAvg(inputs)\n",
    "    trnEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    trnLbls[i*batchSize: (i+1)*batchSize] = labels\n",
    "\n",
    "labels_test = torch.tensor(encoded_labels_test).long()\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(idsTst.int(), labels_test)), batch_size=batchSize,\n",
    "                                         shuffle=True)\n",
    "tstEmbdngs = np.zeros((idsTst.shape[0],dim))\n",
    "tstLbls  = np.zeros((idsTst.shape[0]))\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs,labels = data\n",
    "    outputs = modelw2vAvg(inputs)\n",
    "    tstEmbdngs[i*batchSize: (i+1)*batchSize,:] = outputs.detach().clone().numpy()\n",
    "    tstLbls[i*batchSize: (i+1)*batchSize] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel = 'linear')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyLnr = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyLnr = clf.score(tstEmbdngs,tstLbls)\n",
    "print(TrnAccrcyLnr)\n",
    "print(TstAccrcyLnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel='rbf')\n",
    "clf.fit(trnEmbdngs, trnLbls)\n",
    "TrnAccrcyKernel = clf.score(trnEmbdngs, trnLbls)\n",
    "TstAccrcyKernel = clf.score(tstEmbdngs,tstLbls)\n",
    "print(TrnAccrcyKernel)\n",
    "print(TstAccrcyKernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
